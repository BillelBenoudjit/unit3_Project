{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc183445",
   "metadata": {},
   "source": [
    "<img src=\"Logo.png\" width=\"100\" align=\"left\"/> \n",
    "\n",
    "# <center> Unit 3 Project </center>\n",
    "#  <center> Third section : supervised task </center>\n",
    "\n",
    "In this notebook you will be building and training a supervised learning model to classify your data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be234200",
   "metadata": {},
   "source": [
    "For this task we will be using another classification model \"The random forests\" model.\n",
    "\n",
    "Steps for this task: \n",
    "1. Load the already clustered dataset \n",
    "2. Take into consideration that in this task we will not be using the already added column \"Cluster\" \n",
    "3. Split your data.\n",
    "3. Build your model using the SKlearn RandomForestClassifier class \n",
    "4. classify your data and test the performance of your model \n",
    "5. Evaluate the model ( accepted models should have at least an accuracy of 86%). Play with hyper parameters and provide a report about that.\n",
    "6. Provide evidence on the quality of your model (not overfitted good metrics)\n",
    "7. Create a new test dataset that contains the testset + an additional column called \"predicted_class\" stating the class predicted by your random forest classifier for each data point of the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca14fca",
   "metadata": {},
   "source": [
    "## 1. Load the data and split the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34235ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "89b318b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ALB</th>\n",
       "      <th>ALP</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>BIL</th>\n",
       "      <th>CHE</th>\n",
       "      <th>CHOL</th>\n",
       "      <th>CREA</th>\n",
       "      <th>GGT</th>\n",
       "      <th>PROT</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.5</td>\n",
       "      <td>52.5</td>\n",
       "      <td>7.7</td>\n",
       "      <td>22.1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>6.93</td>\n",
       "      <td>3.23</td>\n",
       "      <td>106.0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>69.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.5</td>\n",
       "      <td>70.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>11.17</td>\n",
       "      <td>4.80</td>\n",
       "      <td>74.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>76.5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.9</td>\n",
       "      <td>74.7</td>\n",
       "      <td>36.2</td>\n",
       "      <td>52.6</td>\n",
       "      <td>6.1</td>\n",
       "      <td>8.84</td>\n",
       "      <td>5.20</td>\n",
       "      <td>86.0</td>\n",
       "      <td>33.2</td>\n",
       "      <td>79.3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.2</td>\n",
       "      <td>52.0</td>\n",
       "      <td>30.6</td>\n",
       "      <td>22.6</td>\n",
       "      <td>18.9</td>\n",
       "      <td>7.33</td>\n",
       "      <td>4.74</td>\n",
       "      <td>80.0</td>\n",
       "      <td>33.8</td>\n",
       "      <td>75.7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.2</td>\n",
       "      <td>74.1</td>\n",
       "      <td>32.6</td>\n",
       "      <td>24.8</td>\n",
       "      <td>9.6</td>\n",
       "      <td>9.15</td>\n",
       "      <td>4.32</td>\n",
       "      <td>76.0</td>\n",
       "      <td>29.9</td>\n",
       "      <td>68.7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Category  Age  Sex   ALB   ALP   ALT   AST   BIL    CHE  CHOL   CREA  \\\n",
       "0   1       0.0   32  0.0  38.5  52.5   7.7  22.1   7.5   6.93  3.23  106.0   \n",
       "1   2       0.0   32  0.0  38.5  70.3  18.0  24.7   3.9  11.17  4.80   74.0   \n",
       "2   3       0.0   32  0.0  46.9  74.7  36.2  52.6   6.1   8.84  5.20   86.0   \n",
       "3   4       0.0   32  0.0  43.2  52.0  30.6  22.6  18.9   7.33  4.74   80.0   \n",
       "4   5       0.0   32  0.0  39.2  74.1  32.6  24.8   9.6   9.15  4.32   76.0   \n",
       "\n",
       "    GGT  PROT  cluster  \n",
       "0  12.1  69.0        3  \n",
       "1  15.6  76.5        3  \n",
       "2  33.2  79.3        3  \n",
       "3  33.8  75.7        3  \n",
       "4  29.9  68.7        3  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To-Do:  load the data \n",
    "df = pd.read_csv('clustered_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9d2bdcc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age', 'Sex', 'ALB', 'ALP', 'ALT', 'AST', 'BIL', 'CHE', 'CHOL', 'CREA', 'GGT', 'PROT']\n",
      "(615, 12)\n"
     ]
    }
   ],
   "source": [
    "# To-Do : keep only the columns to be used : all features except ID, cluster \n",
    "# The target here is the Category column \n",
    "# Do not forget to split your data (this is a classification task)\n",
    "# test set size should be 20% of the data \n",
    "\n",
    "# Keep only columns to use\n",
    "df_cols = list(df.columns)\n",
    "cols = df_cols[2:len(df_cols)-1]\n",
    "print(cols)\n",
    "# Get target\n",
    "y = df['Category']\n",
    "# Get data using right columns\n",
    "X = df[cols].copy()\n",
    "# Split the data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523519ae",
   "metadata": {},
   "source": [
    "## 2. Building the model and training and evaluate the performance: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ea837ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'entropy', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# To-do build the model and train it \n",
    "# note that you will be providing explanation about the hyper parameter tuning \n",
    "# So you will be iterating a number of times before getting the desired performance \n",
    "\n",
    "# Create the base model to tune\n",
    "rf = RandomForestClassifier(n_estimators = 100, criterion ='entropy', random_state = 0)\n",
    "# Check the different params of the classifier\n",
    "print(model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62097d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Using RandomizedSearchCV to get best params\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Create a random grid to train the model on\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4e1f1bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=RandomForestClassifier(criterion='entropy',\n",
       "                                                    random_state=0),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier(n_estimators = 100, criterion ='entropy', random_state = 0)\n",
    "# Random search of parameters, using 3 fold cross validation (We use cross validation to avoid overfitting), \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37b8934a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest model accuracy: 93.4959349593496 %\n",
      "Random forest model precision: 93.4959349593496 %\n"
     ]
    }
   ],
   "source": [
    "# To-do : evaluate the model in terms of accuracy and precision \n",
    "# Provide evidence that your model is not overfitting \n",
    "y_hat = rf_random.predict(X_valid)\n",
    "from sklearn.metrics import precision_score, accuracy_score\n",
    "print('Random forest model accuracy:', accuracy_score(y_valid, y_hat)*100,\"%\")\n",
    "print('Random forest model precision:', precision_score(y_valid, y_hat, average='micro')*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55598bf2",
   "metadata": {},
   "source": [
    "> Hint : A Perfect accuracy on the train set suggest that we have an overfitted model So the student should be able to provide a detailed table about the hyper parameters / parameters tuning with a good conclusion stating that the model has at least an accuracy of 86% on the test set without signs of overfitting  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b9a41c",
   "metadata": {},
   "source": [
    "## 3. Create the summary test set with the additional predicted class column: \n",
    "In this part you need to add the predicted class as a column to your test dataframe and save this one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "428a1032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-Do : create the complete test dataframe : it should contain all the feature column + the actual target and the ID as well  \n",
    "test_df = X_valid.copy()\n",
    "test_df['Category'] = df['Category']\n",
    "test_df['ID'] = df['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8292941c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123, 14)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3d90512a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-Do : Add the predicted_class column \n",
    "test_df[\"Predicted_class\"] = y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1d81bd95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123, 15)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485bf1ca",
   "metadata": {},
   "source": [
    "> Make sure you have 16 column in this test set  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a0f354df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the test set \n",
    "test_df.to_csv(\"test_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3954d7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
